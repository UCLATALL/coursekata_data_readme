---
title: "Examples for handling class data"
output: html_notebook
---

# Required Packages and Helper Functions

To use the code in these examples you will need a handful of useful packages. Here is the code to install them:

```{r setup, echo = FALSE}

# load required packages, installing if needed
if (!require("pacman")) install.packages("pacman")
pacman::p_load(jsonlite, dplyr, readr, purrr, lubridate)

# define some helper functions that will be useful later
json_to_list <- function(x) {
  if (is.null(x) | is.na(x)) list() else parse_json(x)
}
```

# Loading Class Data

Data from the class is split into four tables with each table in its own file. Below is the code to load each table, and a description of the contents of each table.

## Response Data

```{r}
# for responses, the number of columns is variable so we don't know the types
# readr will try to guess the types, but col_guess() is unreliable
# instead just read everything in as a character column and then convert after
responses <- "responses.csv" %>% 
  read_csv(col_types = cols(.default = col_character())) %>% 
  mutate_at(vars(correct), parse_logical) %>% 
  mutate_at(vars(attempt, lrn_question_position), parse_integer) %>% 
  mutate_at(vars(matches("^(?:lrn_)?dt_")), parse_datetime) %>% 
  mutate_at(vars(lrn_score, lrn_max_score), parse_number) %>% 
  # convert response JSON to a nested list-column then move it to the end
  mutate(lrn_response_json = map(lrn_response_json, json_to_list)) %>% 
  select(-lrn_response_json, lrn_response_json)

glimpse(responses)
```

## Page Views

The page view data comes in a table of student-page-datetime cases. That is, there is a row for every time a student accessed a page in the course. The table has five variables:
 - *class_id*: a unique identifier for this particular class
 - *student_id*: a unique identifier for each student on CourseKata
 - *chapter*: the chapter the page view occurred in
 - *page*: the page that was viewed
 - *dt_accessed*: a datetime object indicating when the page was accessed (timezone: GMT/UTC)

```{r read-in page views}
page_views <- "page-views.csv" %>% 
  read_csv(col_types = cols(.default = col_character())) %>% 
  mutate(
    # read in as UTC and then convert to system timezone
    dt_accessed = ymd_hms(dt_accessed, tz = "UTC"),
    dt_accessed = with_tz(dt_accessed, Sys.timezone())
  )

glimpse(page_views)
```

## Items

Items are organized in a table where each row represents all of the data for a particular question in the class. There are 18 columns in the table, though they will never *all* be relevant for a particular item. Columns prefixed with "dcl_" are only filled for DataCamp-Light items (the R-sandboxes) and columns prefixed with "lrn_" are only filled for Learnosity items. Here are descriptions of the columns in the table:
 - *class_id*: a unique identifier for this particular class
 - *item_id*: a unique identifier for this particular question
 - *item_type*: whether this is a *learnosity* or *datacamp* item
 - *chapter*: the chapter that the item appears in
 - *page*: the page that the item appears on
 - *dcl_pre_exercise_code*: the code run invisibly to set up the module
 - *dcl_sample_code*: the code in the module when it first loads
 - *dcl_solution*: the code that appears in the solution tab
 - *dcl_sct*: the solution checking code (see the testwhat package for details)
 - *dcl_hint*: the text that appears in the hint box
 - *lrn_activity_reference*: the unique ID for the activity on Learnosity
 - *lrn_question_reference*: the unique ID for the question on Learnosity
 - *lrn_question_position*: for multi-question items, the position of the question in the item
 - *lrn_template_name*: the template used to create the item
 - *lrn_template_reference*: a unique ID for the item template on Learnosity
 - *lrn_item_status*: the status of the item on Learnosity (e.g. "published")
 - *lrn_question_data*: the fully-detailed JSON object that sets up the item
 
For more about the distinction between Learnosity Activities, Items, and Questions, see the documenation at https://authorguide.learnosity.com/hc/en-us.

```{r}
items <- "items.csv" %>% 
  read_csv(col_types = cols(.default = col_character())) %>% 
  mutate(
    lrn_question_position = parse_integer(lrn_question_position),
    lrn_question_data = map(lrn_question_data, json_to_list)
  )

glimpse(items)
```

## Tags 

Tags are not currently utilized heavily within CourseKata but may have a larger role in the future (e.g. tagging specific learning outcomes). For completeness, the table is described here, but it will likely not be of much use. 

The tags table is organized at the item-tag level where each tag for each item has its own row. There are three columns in the table:
 - *item_id*: a unique identifier for this particular question
 - *tag*: the tag given to this item
 - *tag_type*: the hierarchical parent tag for this tag (e.g. "Chapter" holds all of the chapter name tags)

```{r}
tags <- "tags.csv" %>% 
  read_csv(col_types = cols(.default = col_character()))

glimpse(tags)
```

# Working With Class Data

## Split the Response Data

Though all of the responses have been read into the `responses` table, there are a lot of different types of responses lumped into the one file. One thing that might helps is to make some semantic splits into the survey items, in-text items, and practice quizzes. Since the survey items are (generally) static trait questions like demographics, those can go into a `students` table, and the others into `textbook_items` and `practice_quizzes`.

```{r}

```
